---
subtitle: Introduction to Python
title: Scikit-learn
author: Javier Paris
---

# Introduction to Scikit-learn

## What is scikit-learn?

::: {.columns}
:::: {.column width=50%}

Scikit-learn is a Python library that provides a large number of machine learning algorithms, as well as tools for working with data and evaluating models.

<https://scikit-learn.org/stable/>

::::
:::: {.column width=50%}

![](../resources/images/sklearn.png){width=100% fig-align="center"}

::::
:::

## Installation

By default, scikit-learn is already installed in various Python development environments, such as Anaconda or Jupyter Notebook (Google Colab).

To install scikit-learn in your local environment, you can do so using pip:

``` {.bash}
pip install scikit-learn
```

or from a Jupyter notebook:

``` {.python}
!pip install scikit-learn
```

## Importing scikit-learn

Like any library in Python, we must first import it to use it.
Scikit-learn is a very large library, where we usually use specific submodules.
It is common to import only the parts we are going to use.

``` {python}
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
```

# Methods for Validation

## Example

To illustrate this section, we will use the following dataset and model:

``` {python}
#| output: false
#| echo: false
import pandas as pd
pd.set_option('display.float_format', lambda x: f'{x:.2e}')
```

``` {python}
import pandas as pd
df = pd.read_csv("https://raw.githubusercontent.com/jparisu/CUNEF-ML-Resources/main/datasets/imdb/imdb.csv")  # Load the dataset
df.drop(columns=["c_box_office", "c_profit", "adult"], inplace=True)  # Drop 2
print(df)
```

## Train-Test Split

Scikit-learn provides a function to split a dataset into two subsets: `train_test_split`.
The following parameters can be used:

- `test_size`: size of the test set. If it is a `float`, it represents the proportion of the test set. If it is an `int`, it represents the number of samples.
- `random_state`: seed for random number generation.

::: {.columns}
:::: {.column width=70%}

``` {python}
X = df.drop(columns=["c_performance"])  # Features
y = df["c_performance"]  # Target variable
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)  # Split the dataset
print(X_train)
```

::::
:::: {.column width=30%}

``` {python}
print(y_train)
```

::::
:::

## Train-Test Split - stratify

The `stratify` argument allows for stratified splitting of the data, maintaining the class proportions in both subsets.

::: {.columns}
:::: {.column width=70%}

``` {python}
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42, stratify=y)  # Split the dataset
print(X_train)
```

::::
:::: {.column width=30%}

``` {python}
print(y_train)
```

::::
:::

## K-Fold Cross Validation

To implement *K-Fold Cross Validation* in scikit-learn:

::: {.columns}
:::: {.column width=70%}

``` {python}
from sklearn.model_selection import KFold
kf = KFold(n_splits=3, shuffle=True, random_state=42)
for train_index, test_index in kf.split(X):
    print(X.iloc[test_index])
    print()
```

::::
:::: {.column width=30%}

``` {python}
for train_index, test_index in kf.split(X):
    print(y.iloc[test_index])
    print()
```

::::
:::

# Methods for Evaluation - Classification

## Example

To illustrate this section, we will use the following dataset and model:

``` {python}
from sklearn.neighbors import KNeighborsClassifier
df = pd.read_csv("https://raw.githubusercontent.com/jparisu/CUNEF-ML-Resources/main/datasets/imdb/imdb.csv")  # Load the dataset
df.drop(columns=["c_box_office", "c_profit", "genre", "name"], inplace=True)
df.replace({"adult": {"yes": 1, "no": 0}}, inplace=True)
X = df.drop(columns=["c_performance"])  # Features
y = df["c_performance"]  # Target variable
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=22, stratify=y)  # Split the dataset
model = KNeighborsClassifier(n_neighbors=3)  # Create a model
_ = model.fit(X_train, y_train)  # Train the model
```

\

::: {.columns}
:::: {.column width=40%}
``` {python}
print(X_test)
```
::::
:::: {.column width=30%}
``` {python}
print(y_test)
```
::::
:::: {.column width=30%}
``` {python}
predicted = pd.Series(model.predict(X_test), index=X_test.index)
print(predicted)
```
::::
:::

## Overall Accuracy

To measure the overall accuracy of a classification model, we can use the `accuracy_score` function.

``` {python}
from sklearn.metrics import accuracy_score
print(accuracy_score(y_test, predicted))
```

## Precision, Recall, and F1-Score

To obtain the precision, recall, and F1-score of a classification model, we use the functions `precision_score`, `recall_score`, and `f1_score`.

``` {python}
from sklearn.metrics import precision_score, recall_score, f1_score
print(f"Precision: {precision_score(y_test, predicted, pos_label='expected'):.3f}")
print(f"Recall: {recall_score(y_test, predicted, pos_label='expected'):.3f}")
print(f"F1-score: {f1_score(y_test, predicted, pos_label='expected'):.3f}")
```

## Classification Report

Scikit-learn provides a function to obtain a classification report for a classification model: `classification_report`.

``` {python}
from sklearn.metrics import classification_report
print(classification_report(y_test, predicted))
```

## Confusion Matrix

To obtain the confusion matrix of a classification model, we can use the `confusion_matrix` function.

``` {python}
from sklearn.metrics import confusion_matrix
print(confusion_matrix(y_test, predicted))
```

# Models for Classification

## K-NN

We can create a K-NN classification model with scikit-learn using the `KNeighborsClassifier` class.

- `n_neighbors`: number of neighbors to consider.

``` {python}
from sklearn.neighbors import KNeighborsClassifier
model = KNeighborsClassifier(n_neighbors=3)  # Create a model
_ = model.fit(X_train, y_train)  # Train the model
print(f"Accuracy: {accuracy_score(y_test, model.predict(X_test)):.3f}")
print(f"F1-score: {f1_score(y_test, model.predict(X_test), pos_label='expected'):.3f}")
```

## Logistic Regression

We can create a logistic regression classification model with scikit-learn using the `LogisticRegression` class.

- `max_iter`: maximum number of iterations.

``` {python}
from sklearn.linear_model import LogisticRegression
model = LogisticRegression(max_iter=1000)  # Create a model
_ = model.fit(X_train, y_train)  # Train the model
print(f"Accuracy: {accuracy_score(y_test, model.predict(X_test)):.3f}")
print(f"F1-score: {f1_score(y_test, model.predict(X_test), pos_label='expected'):.3f}")
```

## Naive Bayes

We can create a Naive Bayes classification model with scikit-learn using the `GaussianNB` class.

``` {python}
from sklearn.naive_bayes import GaussianNB
model = GaussianNB()  # Create a model
_ = model.fit(X_train, y_train)  # Train the model
print(f"Accuracy: {accuracy_score(y_test, model.predict(X_test)):.3f}")
print(f"F1-score: {f1_score(y_test, model.predict(X_test), pos_label='expected'):.3f}")
```

## Decision Trees

We can create a decision tree classification model with scikit-learn using the `DecisionTreeClassifier` class.

``` {python}
from sklearn.tree import DecisionTreeClassifier
model = DecisionTreeClassifier()  # Create a model
_ = model.fit(X_train, y_train)  # Train the model
print(f"Accuracy: {accuracy_score(y_test, model.predict(X_test)):.3f}")
print(f"F1-score: {f1_score(y_test, model.predict(X_test), pos_label='expected'):.3f}")
```


# Methods for Evaluation - Regression

## Example

To illustrate this section, we will use the following dataset and model:

``` {python}
from sklearn.linear_model import LinearRegression
df = pd.read_csv("https://raw.githubusercontent.com/jparisu/CUNEF-ML-Resources/main/datasets/imdb/imdb.csv")  # Load the dataset
df.drop(columns=["c_performance", "c_profit", "genre", "name"], inplace=True)
df.replace({"adult": {"yes": 1, "no": 0}}, inplace=True)
X = df.drop(columns=["c_box_office"])  # Features
y = df["c_box_office"]  # Target variable
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=13)  # Split the dataset
model = LinearRegression()  # Create a model
_ = model.fit(X_train, y_train)  # Train the model
```

\

::: {.columns}
:::: {.column width=30%}
``` {python}
print(X_test)
```
::::
:::: {.column width=20%}
``` {python}
print(y_test)
```
::::
:::: {.column width=20%}
``` {python}
predicted = pd.Series(model.predict(X_test), index=X_test.index)
print(predicted)
```
::::
:::: {.column width=20%}
``` {python}
print(predicted - y_test)
```
::::
:::

## Mean Absolute Error

To obtain the mean absolute error of a regression model, we can use the `mean_absolute_error` function.

``` {python}
from sklearn.metrics import mean_absolute_error
print(f"MAE: {mean_absolute_error(y_test, predicted):.2e}")
```


## Mean Squared Error

To obtain the mean squared error of a regression model, we can use the `mean_squared_error` and `root_mean_squared_error` functions.

``` {python}
from sklearn.metrics import mean_squared_error, root_mean_squared_error
print(f"MSE: {mean_squared_error(y_test, predicted):.2e}")
print()
print(f"RMSE: {root_mean_squared_error(y_test, predicted):.2e}")
```

## R2

To obtain the coefficient of determination of a regression model, we can use the `r2_score` function.

``` {python}
from sklearn.metrics import r2_score
print(r2_score(y_test, predicted))
```


# Models for Regression

## Linear Regression

We can create a linear regression model with scikit-learn using the `LinearRegression` class.

``` {python}
from sklearn.linear_model import LinearRegression
model = LinearRegression()  # Create a model
_ = model.fit(X_train, y_train)  # Train the model
print(f"MAE: {mean_absolute_error(y_test, model.predict(X_test)):.2e}")
print(f"R2: {r2_score(y_test, model.predict(X_test)):.3f}")
```

## Linear Regression - Regularization

We can create a linear regression model with regularization using the `Ridge` or `Lasso` classes in scikit-learn.

- `alpha`: regularization strength parameter.


::: {.columns}
:::: {.column width=49%}

``` {python}
from sklearn.linear_model import Ridge
model = Ridge(alpha=0.1)  # Create a model
_ = model.fit(X_train, y_train)  # Train the model
print(f"MAE: {mean_absolute_error(y_test, model.predict(X_test)):.2e}")
print(f"R2: {r2_score(y_test, model.predict(X_test)):.3f}")
print()
print(f"Coefficients: {model.coef_}")
```

::::
:::: {.column width=49%}

``` {python}
from sklearn.linear_model import Lasso
model = Lasso(alpha=0.1)  # Create a model
_ = model.fit(X_train, y_train)  # Train the model
print(f"MAE: {mean_absolute_error(y_test, model.predict(X_test)):.2e}")
print(f"R2: {r2_score(y_test, model.predict(X_test)):.3f}")
print()
print(f"Coefficients: {model.coef_}")
```

::::
:::


# Models for Clustering

## K-Means

We can create a K-Means clustering model with scikit-learn using the `KMeans` class.

- `n_clusters`: number of clusters to create.

``` {python}
from sklearn.cluster import KMeans
model = KMeans(n_clusters=3)  # Create a model
_ = model.fit(X)  # Train the model
df['cluster'] = model.labels_
print(df)
```

# Other Models

## Other Models

Within scikit-learn, we can find a large number of machine learning algorithms, such as:

- **SVM**: `from sklearn.svm import SVC`
- **K-NN** (regression): `from sklearn.neighbors import KNeighborsRegressor`
- **Random Forest** (classification): `from sklearn.ensemble import RandomForestClassifier`
- **Random Forest** (regression): `from sklearn.ensemble import RandomForestRegressor`
- **XGBoost**: `from xgboost import XGBClassifier`

## Neural Networks

Scikit-learn can provide basic classes to work with neural networks.
However, the great complexity and computational cost they usually require has led to the development of specialized libraries for working with them.

The most popular are:

- **TensorFlow**: <https://www.tensorflow.org/>
- **Keras**: <https://keras.io/> (abstraction layer for TensorFlow)
- **PyTorch**: <https://pytorch.org/>

# Conclusion

## Conclusions

- Scikit-learn is a very comprehensive Python library for working with machine learning.
- It provides a large number of machine learning algorithms.
- It provides tools for working with data and evaluating models.
